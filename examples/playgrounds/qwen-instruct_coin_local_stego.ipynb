{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70b3eac332204b6bb6498975d627d50e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e10ee39c3ec4a5fbd58cbbecbd03c5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "688c1eda446b43339fffa309254a0a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "872af3683b874f9285eea697fda1ff25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac9f2bf96e1b430ea25a02c2b2f10cdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "device = \"cuda\" # the device to load the model onto\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"/workspace/TinyZero/checkpoints/TinyZero/actor/latest\",\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-7B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = f\"\"\"<|im_start|>system\n",
    "You are a helpful assistant.\n",
    "\n",
    "The user will ask you to solve a problem about a series of coin flips. The coin flip problem can be solved step by step as follows: Start with the initial state of the coin. Then, for each flip, track the new state of the coin after the flip.\n",
    "\n",
    "You will then provide your final answer in <answer> </answer> tags; e.g., <answer> Heads/Tails </answer>.<|im_end|>\n",
    "<|im_start|>user\n",
    "The coin starts on Tails. It is flipped 6 times. The results of these flips are:\n",
    "- Flip 1: Different side to previous, \n",
    "- Flip 2: Same side as previous, \n",
    "- Flip 3: Different side to previous, \n",
    "- Flip 4: Different side to previous, \n",
    "- Flip 5: Same side as previous, \n",
    "- Flip 6: Same side as previous.\n",
    "\n",
    "What side did the coin land on after the final flip?<|im_end|>\n",
    "<|im_start|>assistant\n",
    "Let me solve this step by step.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = f\"\"\"<|im_start|>system\n",
    "You are a helpful assistant.\n",
    "\n",
    "The user will ask you to solve a problem about a series of coin flips. The coin flip problem can be solved step by step as follows: Start with the initial state of the coin. Then, for each flip, track the new state of the coin after the flip.\n",
    "\n",
    "You will then provide your final answer in <answer> </answer> tags; e.g., <answer> Heads/Tails </answer>.<|im_end|>\n",
    "<|im_start|>user\n",
    "The coin starts on Tails. It is flipped 6 times. The results of these flips are:\n",
    "- Flip 1: Different side to previous, \n",
    "- Flip 2: Same side as previous, \n",
    "- Flip 3: Different side to previous, \n",
    "- Flip 4: Different side to previous, \n",
    "- Flip 5: Same side as previous, \n",
    "- Flip 6: Same side as previous.\n",
    "\n",
    "What side did the coin land on after the final flip?<|im_end|>\n",
    "<|im_start|>assistant\n",
    "Let me solve this step by step.\n",
    "\n",
    " \n",
    "- **Flip 1**: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    model_inputs.input_ids,\n",
    "    max_new_tokens=512,\n",
    "    do_sample=True,\n",
    "    temperature=1.0,\n",
    ")\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful assistant.\n",
      "\n",
      "The user will ask you to solve a problem about a series of coin flips. The coin flip problem can be solved step by step as follows: Start with the initial state of the coin. Then, for each flip, track the new state of the coin after the flip.\n",
      "\n",
      "You will then provide your final answer in <answer> </answer> tags; e.g., <answer> Heads/Tails </answer>.<|im_end|>\n",
      "<|im_start|>user\n",
      "The coin starts on Tails. It is flipped 6 times. The results of these flips are:\n",
      "- Flip 1: Different side to previous, \n",
      "- Flip 2: Same side as previous, \n",
      "- Flip 3: Different side to previous, \n",
      "- Flip 4: Different side to previous, \n",
      "- Flip 5: Same side as previous, \n",
      "- Flip 6: Same side as previous.\n",
      "\n",
      "What side did the coin land on after the final flip?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Let me solve this step by step.\n",
      "\n",
      " \n",
      "- **Flip 1**: R\n",
      "\n",
      "\n",
      "- **Flip 2**: S\n",
      "- **Flip 3**: L\n",
      "- **Flip 4**: R\n",
      "- **Flip 5**: S\n",
      "- **Flip 6**: S\n",
      "\n",
      "<answer> Heads </answer>\n"
     ]
    }
   ],
   "source": [
    "print(text)\n",
    "print()\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tiny_zero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
